{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 1.1\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "#Step1: Simulate a dice roll\n",
    "def roll_dice():\n",
    "    return random.randint(1, 6)\n",
    "\n",
    "# Simulate a session of dice rolls\n",
    "def simulate_session(k):\n",
    "    return [roll_dice() for _ in range(k)]\n",
    "\n",
    "# Calculate the statistics for a session\n",
    "def calculate_statistics(session):\n",
    "    z6 = session.count(6)\n",
    "    q6 = z6 / len(session)\n",
    "    x_bar = sum(session) / len(session)\n",
    "    x_median = np.median(session)\n",
    "    return z6, q6, x_bar, x_median\n",
    "\n",
    "# Simulate multiple sessions and calculate the statistics for each session\n",
    "def simulate_sessions(n, k):\n",
    "    sessions = [simulate_session(k) for _ in range(n)]\n",
    "    statistics = [calculate_statistics(session) for session in sessions]\n",
    "    return statistics\n",
    "\n",
    "# Plot the histogram of the statistics\n",
    "def plot_histogram(statistics):\n",
    "    z6s, q6s, x_bars, x_medians = zip(*statistics)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(z6s, bins=range(1, 7), edgecolor='black')\n",
    "    plt.title('z6')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(q6s, bins=10, edgecolor='black')\n",
    "    plt.title('q6')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(x_bars, bins=10, edgecolor='black')\n",
    "    plt.title('x_bar')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(x_medians, bins=range(1, 7), edgecolor='black')\n",
    "    plt.title('x_median')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the simulation for different values of n and k\n",
    "for n, k in [(100, 10), (1000, 10), (100, 100), (1000, 100)]:\n",
    "    print(f\"n={n}, k={k}\")\n",
    "    statistics = simulate_sessions(n, k)\n",
    "    plot_histogram(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when n=100 and k=10 the histograms for the statistics will show significant variability due to the smaller number of rolls per session.\n",
    "The distribution might not be smooth, and the calculated statistics might vary more from session to session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when n=1000 and k=10  the larger amount of sessions will make the histograms start to smooth out, providing a accurate display of the distributions.\n",
    "However, since k is still small, there will still be significant variability within each session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When n=100 and k=100 each session will be more stable because the sample size is much larger within each session. The histograms will be smoother and closer to the theoretical distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when n=1000 and k=100 The data will result in a smooth and reliable histogram which will match the theoretical distributions most of the time. This is because both the number of sessions and the amount of rolls per session is big enough to expect low variability and an accurate approximation of the theoretical distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small N leads to less smooth histograms and a big n to smoother histograms.\n",
    "A small K leads to more variability and a big k to more stability and reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 1.2\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simulate_die_rolls(k):\n",
    "    return np.random.randint(1, 7, k)\n",
    "\n",
    "def calculate_average(rolls):\n",
    "    return np.mean(rolls)\n",
    "\n",
    "def simulate_n_experiments(n, k):\n",
    "    averages = []\n",
    "    for _ in range(n):\n",
    "        rolls = simulate_die_rolls(k)\n",
    "        averages.append(calculate_average(rolls))\n",
    "    return averages\n",
    "\n",
    "def plot_histogram(averages):\n",
    "    plt.hist(averages, bins='auto', edgecolor='black')\n",
    "    plt.title('Histogram of Average Outcomes')\n",
    "    plt.xlabel('Average Outcome')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "def determine_bounds(averages):\n",
    "    Tlower = np.percentile(averages, 2.5)\n",
    "    Tupper = np.percentile(averages, 97.5)\n",
    "    return Tlower, Tupper\n",
    "\n",
    "def is_die_fair(Tsample, Tlower, Tupper):\n",
    "    return Tlower <= Tsample <= Tupper\n",
    "\n",
    "\n",
    "n = 1000  # Number of experiments\n",
    "k = 30    # Number of rolls per experiment\n",
    "averages = simulate_n_experiments(n, k)\n",
    "plot_histogram(averages)\n",
    "Tlower, Tupper = determine_bounds(averages)\n",
    "Tsample = calculate_average(simulate_die_rolls(k))  # Test statistic from a new sample\n",
    "print(f\"Die is fair: {is_die_fair(Tsample, Tlower, Tupper)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The die is fair when the dice has an equal probability landing face up when the dice is rolled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEEK 7 Assignment 1 fair die\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ASSIGNMENT 1\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Rolling a die 30 times\n",
    "rolls = np.array([1, 3, 5, 2, 4, 4, 3, 1, 5, 6, 3, 4, 3, 6, 2, 4, 6, 4, 5, 4, 2, 3, 4, 6, 5, 1, 5, 6, 5, 4]) #Fille in its outcome\n",
    "\n",
    "# Calculate observed frequencies\n",
    "observed_frequencies = np.bincount(rolls, minlength=7)[1:] # Assuming die faces are 1 through 6\n",
    "\n",
    "# Calculate expected frequencies for a fair dice\n",
    "k = len(rolls) #Total number of rolls\n",
    "expected_frequencies = np.array([k / 6] * 6) # Fair die expectation\n",
    "\n",
    "# chi-squared test\n",
    "chi_square_stat, p_value = stats.chisquare(observed_frequencies, expected_frequencies)\n",
    "print(f\"Chi-squared Statistics: {chi_square_stat}, P-value: {p_value}\")\n",
    "\n",
    "# use the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is significance evidence to suggest the die is biased then the dice is not fair.\")\n",
    "else:\n",
    "    print(\"There is not significance evidence to suggest the die is biased, so the dice is fair.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows that the die is fair because the numbers rolled were reasonably varied and the P-value is high enough to conclude that this is a totally normal die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEEK 7 Assignment 1 unfair die\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted dice\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Rolling a die 30 times\n",
    "rolls = np.array([2, 3, 3, 6, 6, 6, 4, 1, 4, 6, 5, 2, 2, 2, 6, 2, 2, 4, 2, 2, 2, 6, 2, 2, 4, 2, 2, 2, 5, 2]) #Filled in its outcome\n",
    "\n",
    "# Calculate observed frequencies\n",
    "observed_frequencies = np.bincount(rolls, minlength=7)[1:] # Assuming die faces are 1 through 6\n",
    "\n",
    "# Calculate expected frequencies for a fair dice\n",
    "k = len(rolls) #Total number of rolls\n",
    "expected_frequencies = np.array([k / 6] * 6) # Fair die expectation\n",
    "\n",
    "# Use chi-squared test\n",
    "chi_square_stat, p_value = stats.chisquare(observed_frequencies, expected_frequencies)\n",
    "print(f\"Chi-squared Statistics: {chi_square_stat}, P-value: {p_value}\")\n",
    "\n",
    "# use the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is significance evidence to suggest the die is biased then the dice is not fair.\")\n",
    "else:\n",
    "    print(\"There is not significance evidence to suggest the die is biased, so the dice is fair.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows that the die is unfair due to the significance number of times the 2 was rolled resulting in a low P-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 2.1\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# \n",
    "def roll_fair_die():\n",
    "    return random.randint(1, 6)\n",
    "\n",
    "# \n",
    "def roll_biased_die():\n",
    "    return random.choices([1, 2, 3, 4, 5, 6], weights=[1, 1, 1, 1, 1, 2])[0]\n",
    "\n",
    "# \n",
    "def bootstrap_dataset(original_dataset, k):\n",
    "    return random.choices(original_dataset, k=k)\n",
    "\n",
    "# \n",
    "def calculate_confidence_interval(dataset, confidence=0.95):\n",
    "    return np.percentile(dataset, [(1-confidence)/2*100, (1+confidence)/2*100])\n",
    "\n",
    "# \n",
    "def is_fair(confidence_interval, expected_mean=3.5, expected_q6=1/6):\n",
    "    return confidence_interval[0] <= expected_mean <= confidence_interval[1]\n",
    "\n",
    "# \n",
    "for n, k in [(1000, 10), (100, 10), (1000, 100), (10000, 1000)]:\n",
    "    fair_dataset = [roll_fair_die() for _ in range(k)]\n",
    "    biased_dataset = [roll_biased_die() for _ in range(k)]\n",
    "    for original_dataset in [fair_dataset, biased_dataset]:\n",
    "        bootstrap_datasets = [bootstrap_dataset(original_dataset, k) for _ in range(n)]\n",
    "        means = [np.mean(dataset) for dataset in bootstrap_datasets]\n",
    "        confidence_interval = calculate_confidence_interval(means)\n",
    "        print(f\"n={n}, k={k}, is_fair={is_fair(confidence_interval)}\")\n",
    "\n",
    "# Histogram\n",
    "plt.hist(means, bins=30, alpha=0.5)\n",
    "plt.title('Histogram of means')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 2.2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Define a function roll_dice that simulates dice rolls.\n",
    "def roll_dice(k, sides=6, bias=None):\n",
    "    if bias is None:\n",
    "        bias = [1/sides]*sides\n",
    "    return np.random.choice(range(1, sides+1), size=k, p=bias)\n",
    "\n",
    "def rearrangement(X, Y, n=10000):\n",
    "    diff = np.mean(X) - np.mean(Y)\n",
    "    combined = np.concatenate((X, Y))\n",
    "    diffs = []\n",
    "    for _ in range(n):\n",
    "        np.random.shuffle(combined)\n",
    "        new_X = combined[:len(X)]\n",
    "        new_Y = combined[len(X):]\n",
    "        diffs.append(np.mean(new_X) - np.mean(new_Y))\n",
    "    return diffs, diff\n",
    "\n",
    "# Simulate dice rolls\n",
    "X = roll_dice(100, bias=[0.1, 0.1, 0.1, 0.1, 0.1, 0.5])  # Fake die\n",
    "Y = roll_dice(100)  # Fair die\n",
    "\n",
    "# Perform permutation test\n",
    "diffs, original_diff = rearrangement(X, Y)\n",
    "\n",
    "# Calculate confidence interval\n",
    "lower, upper = np.percentile(diffs, [2.5, 97.5])\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(diffs, bins=30, alpha=0.5)\n",
    "plt.axvline(x=lower, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.axvline(x=upper, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.axvline(x=original_diff, color='b', linestyle='dashed', linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "# Check if difference in means falls within the confidence interval\n",
    "if lower <= original_diff <= upper:\n",
    "    print(\"The dice are likely the same.\")\n",
    "else:\n",
    "    print(\"The dice are likely different.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 7 Assignment 2.1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGNMENT 2 PART1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Collect data\n",
    "scores_before = np.array([2, 2, 2, 3, 2, 5, 4, 3, 2, 2, 1, 2, 4, 5, 1, 2, 5, 3, 2, 2, 3, 3, 1, 5, 3, 5, 1, 3, 3, 3, 3, 3, 3, 3, 4, 2, 1])\n",
    "scores_after = np.array([5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5])\n",
    "\n",
    "# Calculate the test statistic (mean difference)\n",
    "test_statistic = np.mean(scores_after - scores_before)\n",
    "print(f\"Test statistic (mean difference): {test_statistic}\")\n",
    "\n",
    "# Bootstrap function for confidence interval\n",
    "def bootstrap_confidence_interval(data, num_samples=10000, confidence_level=0.95):\n",
    "    bootstrap_means = []\n",
    "    for _ in range(num_samples):\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "    lower_bound = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Calculate confidence interval for the mean difference\n",
    "difference_scores = scores_after - scores_before\n",
    "lower_bound, upper_bound = bootstrap_confidence_interval(difference_scores)\n",
    "print(f\"Confidence interval for mean difference: ({lower_bound}, {upper_bound})\")\n",
    "\n",
    "# Compare the test statistic to the confidence interval\n",
    "if lower_bound <= test_statistic <= upper_bound:\n",
    "    print(\"The test statistic is within the confidence interval. There is not significant evidence that the scores differ.\")\n",
    "else:\n",
    "    print(\"The test statistic is outside the confidence interval. There is significant evidence that the scores differ, suggesting the explanation had an effect.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 7 Assignment 2.2\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGNMENT 2 PART 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# data\n",
    "heights = np.array([178, 183, 175, 196, 189, 190, 180, 190, 180, 189, 186, 195, 175, 185, 180, 182, 190, 158, 166, 196, 169, 176, 161, 172, 171, 165, 172, 156, 177, 182, 176, 171, 157, 185, 194, 173, 185, 168, 180, 184])\n",
    "dutch_heights = heights[:20]\n",
    "international_heights = heights[20:]\n",
    "\n",
    "# Calculate the test statistic (mean difference)\n",
    "test_statistic = np.mean(dutch_heights) - np.mean(international_heights)\n",
    "print(f\"Test statistic (mean difference): {test_statistic}\")\n",
    "\n",
    "# Bootstrap function for confidence interval\n",
    "def bootstrap_mean_difference_confidence_interval(group1, group2, num_samples=10000, confidence_level=0.95):\n",
    "    mean_differences = []\n",
    "    for _ in range(num_samples):\n",
    "        bootstrap_sample1 = np.random.choice(group1, size=len(group1), replace=True)\n",
    "        bootstrap_sample2 = np.random.choice(group2, size=len(group2), replace=True)\n",
    "        mean_differences.append(np.mean(bootstrap_sample1) - np.mean(bootstrap_sample2))\n",
    "    lower_bound = np.percentile(mean_differences, (1 - confidence_level) / 2 * 100)\n",
    "    upper_bound = np.percentile(mean_differences, (1 + confidence_level) / 2 * 100)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Generate confidence interval for the test statistic\n",
    "lower_bound, upper_bound = bootstrap_mean_difference_confidence_interval(dutch_heights, international_heights)\n",
    "print(f\"Confidence interval for mean difference: ({lower_bound}, {upper_bound})\")\n",
    "\n",
    "# Compare the test statistic to the confidence interval\n",
    "if lower_bound <= test_statistic <= upper_bound:\n",
    "    print(\"The test statistic is within the confidence interval. There is not significant evidence that the heights differ.\")\n",
    "else:\n",
    "    print(\"The test statistic is outside the confidence interval. There is significant evidence that the heights of Dutch and international students differ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT 3\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import random\n",
    "\n",
    "def create_datasets(k, a, b, sigma):\n",
    "    # Generates k evenly spaced values for X\n",
    "    X = np.linspace(1, k, k)\n",
    "    \n",
    "    # Create Y1 which is linearly correlated with X\n",
    "    Y1 = a * X + b\n",
    "    \n",
    "    # Create Y2 which adds random noise to Y1 making it not correlated with X\n",
    "    Y2 = a * X + b + np.random.normal(1, sigma, k)\n",
    "    \n",
    "    return X, Y1, Y2\n",
    "\n",
    "    # Plot datasets X vs Y1 and X vs Y2.\n",
    "def plot_datasets(X, Y1, Y2):\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X, Y1)\n",
    "    plt.title('X vs Y1')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X, Y2)\n",
    "    plt.title('X vs Y2')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Calculates Pearson and Spearman Correlation coefficient\n",
    "def calculate_correlation(X, Y):\n",
    "    \n",
    "    pearson_corr, _ = pearsonr(X, Y)\n",
    "    \n",
    "    spearman_corr, _ = spearmanr(X, Y)\n",
    "    \n",
    "    return pearson_corr, spearman_corr\n",
    "\n",
    "def is_correlation_significant(X, Y, n=10000):\n",
    "\n",
    "    # Calculate original correlation coefficients\n",
    "    pearson_corr, spearman_corr = calculate_correlation(X, Y)\n",
    "    \n",
    "    # Bootstrap sampling\n",
    "    temp_corrs = []\n",
    "    for _ in range(n):\n",
    "        # Randomly sample Y without replacement\n",
    "        Y_temp = random.sample(list(Y), len(Y))\n",
    "        temp_corr, _ = pearsonr(X, Y_temp)\n",
    "        temp_corrs.append(temp_corr)\n",
    "    \n",
    "    # Calculate 95% confidence interval\n",
    "    lower, upper = np.percentile(temp_corrs, [2.5, 97.5])\n",
    "    \n",
    "    # Checks if original correlation coefficients are within the confidence interval\n",
    "    return lower <= pearson_corr <= upper, lower <= spearman_corr <= upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "k = 100\n",
    "a = 2\n",
    "b = 3\n",
    "sigma = 10\n",
    "X, Y1, Y2 = create_datasets(k, a, b, sigma)\n",
    "\n",
    "# Plot datasets\n",
    "plot_datasets(X, Y1, Y2)\n",
    "\n",
    "# Correlation coefficients\n",
    "pearson_corr_Y1, spearman_corr_Y1 = calculate_correlation(X, Y1)\n",
    "pearson_corr_Y2, spearman_corr_Y2 = calculate_correlation(X, Y2)\n",
    "print(f'Pearson correlation for Y1: {pearson_corr_Y1}, Spearman correlation for Y1: {spearman_corr_Y1}')\n",
    "print(f'Pearson correlation for Y2: {pearson_corr_Y2}, Spearman correlation for Y2: {spearman_corr_Y2}')\n",
    "\n",
    "# Determine and print if correlations are significant\n",
    "is_pearson_Y1_significant, is_spearman_Y1_significant = is_correlation_significant(X, Y1)\n",
    "is_pearson_Y2_significant, is_spearman_Y2_significant = is_correlation_significant(X, Y2)\n",
    "print(f'Is Pearson correlation for Y1 significant? {is_pearson_Y1_significant}')\n",
    "print(f'Is Spearman correlation for Y1 significant? {is_spearman_Y1_significant}')\n",
    "print(f'Is Pearson correlation for Y2 significant? {is_pearson_Y2_significant}')\n",
    "print(f'Is Spearman correlation for Y2 significant? {is_spearman_Y2_significant}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "k = 10\n",
    "a = 2\n",
    "b = 3\n",
    "sigma = 10\n",
    "X, Y1, Y2 = create_datasets(k, a, b, sigma)\n",
    "\n",
    "# Plot datasets\n",
    "plot_datasets(X, Y1, Y2)\n",
    "\n",
    "# Correlation coefficients\n",
    "pearson_corr_Y1, spearman_corr_Y1 = calculate_correlation(X, Y1)\n",
    "pearson_corr_Y2, spearman_corr_Y2 = calculate_correlation(X, Y2)\n",
    "print(f'Pearson correlation for Y1: {pearson_corr_Y1}, Spearman correlation for Y1: {spearman_corr_Y1}')\n",
    "print(f'Pearson correlation for Y2: {pearson_corr_Y2}, Spearman correlation for Y2: {spearman_corr_Y2}')\n",
    "\n",
    "# Determine and print if correlations are significant\n",
    "is_pearson_Y1_significant, is_spearman_Y1_significant = is_correlation_significant(X, Y1)\n",
    "is_pearson_Y2_significant, is_spearman_Y2_significant = is_correlation_significant(X, Y2)\n",
    "print(f'Is Pearson correlation for Y1 significant? {is_pearson_Y1_significant}')\n",
    "print(f'Is Spearman correlation for Y1 significant? {is_spearman_Y1_significant}')\n",
    "print(f'Is Pearson correlation for Y2 significant? {is_pearson_Y2_significant}')\n",
    "print(f'Is Spearman correlation for Y2 significant? {is_spearman_Y2_significant}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 7 Assignment 3.1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGNMENT 3\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# data\n",
    "data = np.array([\n",
    "    [178, 70], [183, 75], [175, 67], [196, 76], [189, 70], [190, 79], [180, 70], [190, 70],\n",
    "    [180, 71], [189, 74], [186, 73], [195, 74], [175, 68], [185, 70], [180, 71], [182, 70],\n",
    "    [190, 80], [158, 57], [166, 66], [196, 79], [169, 67], [176, 65], [161, 64], [172, 69],\n",
    "    [171, 72], [165, 65], [172, 70], [156, 60], [177, 60], [182, 73], [176, 73], [171, 62],\n",
    "    [157, 63], [185, 81], [194, 95], [173, 72], [185, 61], [168, 68], [180, 77], [184, 70]\n",
    "])\n",
    "\n",
    "# Extract body length and arm length\n",
    "body_length = data[:, 0]\n",
    "arm_length = data[:, 1]\n",
    "\n",
    "# Calculate the Pearson correlation coefficient\n",
    "correlation_coefficient = np.corrcoef(body_length, arm_length)[0, 1]\n",
    "print(f\"Pearson correlation coefficient: {correlation_coefficient}\")\n",
    "\n",
    "# Permutation test for confidence interval\n",
    "def permutation_test(x, y, num_permutations=10000, confidence_level=0.95):\n",
    "    observed_corr = np.corrcoef(x, y)[0, 1]\n",
    "    permuted_corrs = []\n",
    "    for _ in range(num_permutations):\n",
    "        y_permuted = np.random.permutation(y)\n",
    "        permuted_corrs.append(np.corrcoef(x, y_permuted)[0, 1])\n",
    "    lower_bound = np.percentile(permuted_corrs, (1 - confidence_level) / 2 * 100)\n",
    "    upper_bound = np.percentile(permuted_corrs, (1 + confidence_level) / 2 * 100)\n",
    "    return observed_corr, lower_bound, upper_bound\n",
    "\n",
    "observed_corr, lower_bound, upper_bound = permutation_test(body_length, arm_length)\n",
    "print(f\"Confidence interval for correlation coefficient: ({lower_bound}, {upper_bound})\")\n",
    "\n",
    "# Compare the correlation coefficient to the confidence interval\n",
    "if lower_bound <= observed_corr <= upper_bound:\n",
    "    print(\"The correlation coefficient is within the confidence interval. There is not significant evidence of a correlation.\")\n",
    "else:\n",
    "    print(\"The correlation coefficient is outside the confidence interval. There is significant evidence of a correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 7 Assignment 3.2 (Travel time and Travel distance)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "#Collect data\n",
    "data = np.array([\n",
    "    [15, 2], [8, 10], [37, 41], [9, 6], [40, 20],\n",
    "    [9, 6], [40, 20], [40, 10], [20, 70], [90, 20],\n",
    "    [70, 55], [100, 65], [20, 30], [15, 65], [15, 12],\n",
    "    [30, 30], [24, 18], [15, 18], [6, 25], [10, 23],\n",
    "    [15, 25], [11, 67], [7, 14], [20, 17], [13, 63],\n",
    "    [8, 12], [10, 4], [3, 13], [12, 17], [20, 12],\n",
    "    [8, 27], [8, 25], [15, 23], [23, 17], [12, 25], \n",
    "    [5, 11], [10, 26], [15, 18], [25, 56], [13, 59],\n",
    "    [23, 17], [20, 4]\n",
    "])\n",
    "\n",
    "# Extract travel distance and travel time\n",
    "travel_distance = data[:, 0]\n",
    "travel_time = data[:, 1]\n",
    "\n",
    "# Calculate the Pearson correlation coefficient\n",
    "correlation_coefficient = np.corrcoef(travel_distance, travel_time)[0, 1]\n",
    "print(f\"Pearson correlation coefficient: {correlation_coefficient}\")\n",
    "\n",
    "# Permutation test for confidence interval\n",
    "def permutation_test(x, y, num_permutations=10000, confidence_level=0.95):\n",
    "    observed_corr = np.corrcoef(x, y)[0, 1]\n",
    "    permuted_corrs = []\n",
    "    for _ in range(num_permutations):\n",
    "        y_permuted = np.random.permutation(y)\n",
    "        permuted_corrs.append(np.corrcoef(x, y_permuted)[0, 1])\n",
    "    lower_bound = np.percentile(permuted_corrs, (1 - confidence_level) / 2 * 100)\n",
    "    upper_bound = np.percentile(permuted_corrs, (1 + confidence_level) / 2 * 100)\n",
    "    return observed_corr, lower_bound, upper_bound\n",
    "\n",
    "observed_corr, lower_bound, upper_bound = permutation_test(travel_distance, travel_time)\n",
    "print(f\"Confidence interval for correlation coefficient: ({lower_bound}, {upper_bound})\")\n",
    "\n",
    "# Compare the correlation coefficient to the confidence interval\n",
    "if lower_bound <= observed_corr <= upper_bound:\n",
    "    print(\"The correlation coefficient is within the confidence interval. There is not significant evidence of a correlation.\")\n",
    "else:\n",
    "    print(\"The correlation coefficient is outside the confidence interval. There is significant evidence of a correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there is an obvious correlation between travel distance and travel time, our conclusion based on the collected data is that there is no significant correlation. We believe this is because everyone used different modes of transportation, which made the same travel distance have significantly different travel times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 7 Assignment 3.3 (Body height and Travel time)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "#Collect data\n",
    "data = np.array([\n",
    "    [178, 2], [183, 10], [175, 41], [196, 6], [189, 20],\n",
    "    [190, 10], [180, 70], [190, 20], [180, 55], [189, 65],\n",
    "    [186, 30], [195, 65], [175, 12], [185, 30], [180, 18],\n",
    "    [182, 18], [190, 25], [158, 23], [166, 25], [196, 67],\n",
    "    [169, 14], [176, 17], [161, 63], [172, 12], [171, 4],\n",
    "    [165, 13], [172, 17], [156, 12], [177, 27], [182, 25],\n",
    "    [176, 23], [171, 17], [157, 25], [185, 17], [194, 11], \n",
    "    [173, 26], [185, 18], [168, 56], [180, 59], [184, 17],\n",
    "    [180, 4], [184, 4]\n",
    "\n",
    "])\n",
    "\n",
    "# Extract travel distance and travel time\n",
    "body_lenght = data[:, 0]\n",
    "travel_time = data[:, 1]\n",
    "\n",
    "# Calculate the Pearson correlation coefficient\n",
    "correlation_coefficient = np.corrcoef(body_lenght, travel_time)[0, 1]\n",
    "print(f\"Pearson correlation coefficient: {correlation_coefficient}\")\n",
    "\n",
    "# Permutation test for confidence interval\n",
    "def permutation_test(x, y, num_permutations=10000, confidence_level=0.95):\n",
    "    observed_corr = np.corrcoef(x, y)[0, 1]\n",
    "    permuted_corrs = []\n",
    "    for _ in range(num_permutations):\n",
    "        y_permuted = np.random.permutation(y)\n",
    "        permuted_corrs.append(np.corrcoef(x, y_permuted)[0, 1])\n",
    "    lower_bound = np.percentile(permuted_corrs, (1 - confidence_level) / 2 * 100)\n",
    "    upper_bound = np.percentile(permuted_corrs, (1 + confidence_level) / 2 * 100)\n",
    "    return observed_corr, lower_bound, upper_bound\n",
    "\n",
    "observed_corr, lower_bound, upper_bound = permutation_test(body_lenght, travel_time)\n",
    "print(f\"Confidence interval for correlation coefficient: ({lower_bound}, {upper_bound})\")\n",
    "\n",
    "# Compare the correlation coefficient to the confidence interval\n",
    "if lower_bound <= observed_corr <= upper_bound:\n",
    "    print(\"The correlation coefficient is within the confidence interval. There is not significant evidence of a correlation.\")\n",
    "else:\n",
    "    print(\"The correlation coefficient is outside the confidence interval. There is significant evidence of a correlation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
